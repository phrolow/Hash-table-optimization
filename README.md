# Оптимизация хеш-таблиц

Доброго дня всем читающим! В этом проекте я попытался исследовать производительность и возможности оптимизаций хеш-функций.

## О хеш-таблицах

**Хеш-таблица** - структура данных, хранящая пары "ключ-значение" и выполняющая три операции: запись нового значения в ячейку, адрес которой определяется ключом; удаление значения; нахождение значения по ключу.

В этом проекте я работаю с **хеш-таблицами, основанными на методе цепочек**. Такая хеш-таблица представляет собой массив спиков, при этом номер списка, где хранится значение, вычисляется хеш-функцией от ключа; каждое новое значение добавляется в хвост списка. 

![Хуеш-таблица](/images/Hash_table.jpg)

**Хеш-функция** - функция, принимающая массив входных данных произвольной длины и возвращающая битовую последовательность установленной длины. В нашем случае хеш-функции принимают строку и возвращают 32 бита.

Также я активно использую термин **коллизия** - совпадение значений хеш-функций для двух разных ключей.

 ## Входные данные

Понятное дело, рассуждать об оптимизациях всегда стоит с поправкой на железо. Представлю данные своего ноутбука:
 - **Процессор** AMD Ryzen 3 4300U со встроенной видеокартой
 - **Оперативная память** 12 ГБ
 - **ОС** Ubuntu 22.04.2 LTS 64-bit

О софтовой части. Я сохранял в хеш-таблицу английский текст трагедии Шекспира "Гамлет". С целью получить при наилучшем распределении в среднем 10-20 слов в списке, я использовал хеш-таблицу размером **317**; выбор числа также обусловлен тем, что хеш-таблицы, имеющие размером простое число, имеют меньше коллизий. Для таблиц использованы [двусвязные списки](https://github.com/phrolow/List), написанные мной полугодом раннее.

На данном этапе программа скомпилирована без какой-либо оптимизации, в т. ч. без флагов.

 ## Начало работы

Первым делом я прогнал текст через [препроцессор](https://github.com/phrolow/Hash-table-optimization/tree/main/src/Preprocessor), заменяющий все символы, не являющиеся буквами, символом '\0'. Это сделано для упрощения загрузки текста в основную программу и исключения таких ситуаций, когда два одинаковых слова могут быть восприняты как разные (на самом деле, не играет большой роли, однако приближает к реальной ситуации)

Далее я запустил основную программу (hasht). Она считывает текст из файла (с рассчётом на то, что слова уже отделены '\0') и сохраняет в предназначенную для этого структуру. Затем запускается цикл, в каждой итерации которого создаётся хеш-таблица с новой хеш-функцией, и в неё загружается текст. После этого происходит замер суммарного времени поиска каждого слова из текста, а в файл **/data/spreading.csv** сохраняется табличная строка с длинами списков хеш-таблицы.

 ## Сравнение хеш-функций

 ### hash1

![hash1](/images/histogram_hash1.png)

Хеш-функция **hash1** возвращает значение **1** независимо от аргумента. Понятное дело, в силу числа коллизий мы имеем ужасное распределение длин списков и достаточно большое время поиска - **510.684 мс**.

 ### hashLen

![hashFirstLetter](/images/histogram_hashFirstLetter.png)

Хеш-функция **hashFirstLetter** возвращает ASCII-код первой буквы строки. В силу довольно ограниченного диапазона значений опять же наблюдаем множество коллизий, неоптимальное распределение длин списков и далеко не лучшее время поиска - **58,361 мс**.

 ### hashWordLen

![hashWordLen](/images/histogram_hashWordLen.png)

Хеш-функция **hashWordLen** возвращает длину строки (а именно, значение **strlen**). Опять же, диапазон сильно ограничен, коллизий много, распределение плохое (сравнимо с предыдущей функцией), время поиска оказалось даже больше - **75,953 мс**

 ### hashSum

![hashSum](/images/histogram_hashSum.png)

Хеш-функция **hashSum** возвращает сумму ASCII-кодов символов строки. В нашем случае за счёт сравнительно малого размера хеш-таблицы мы получаем не так много коллизий, более равномерное распределение, чем у предыдущих функций, и значительно меньшее время поиска - всего **6,584 мс**. Тем не менее, при достаточно большой хеш-таблице начиная с некоторого номера средняя длина списка бы сильно просела.

 ### hashRol

![hashRol](/images/histogram_hashRol.png)

Хеш-функция **hashRol** вычисляется следующим образом (псевдокод):

> H0 = 0
> Hi+1 = rol(Hi) xor string[i + 1]

, где rol - циклический побитовый сдвиг на один бит влево.

Для более полного понимания привожу код:

```
unsigned int hash = 0;
    
    size_t len = strlen(word);

    for (size_t i = 0; i < len; ++i)
    {
        hash = ((hash >> 31) | (hash << 1)) xor word[i];
    }

    return hash;
```

Наблюдаем довольно равномерное распределение. Время работы - **5,919 мс**

 ### hashRor

![hashRor](/images/histogram_hashRor.png)

Хеш-функция **hashRor** отличается от **hashRol** лишь тем, что вместо циклического сдвига влево использует циклический сдвиг вправо.

Распределение чуть менее равномерное, чем у **hashRol**. Время работы - **6,074 мс**

 ### murmurHash2

![murmurHash2](/images/histogram_murmurHash2.png)

Хеш-функция **murmurHash2** имеет следующий код:

```
const unsigned int m = 0x5bd1e995;
    const unsigned int seed = 0;
    const int r = 24;

    //unsigned int len = WORLD_LENGTH;
    unsigned int len = strlen(word);
    unsigned int h = seed ^ len;

    const unsigned char * data = (const unsigned char *) word;
    unsigned int k = 0;

    while (len >= 4)
    {
        k  = data[0];
        k |= data[1] << 8;
        k |= data[2] << 16;
        k |= data[3] << 24;

        k *= m;
        k ^= k >> r;
        k *= m;

        h *= m;
        h ^= k;

        data += 4;
        len -= 4;
    }

    switch (len)
    {
        case 3:
        h ^= data[2] << 16;
        case 2:
        h ^= data[1] << 8;
        case 1:
        h ^= data[0];
        h *= m;
    };

    h ^= h >> 13;
    h *= m;
    h ^= h >> 15;

    return h;
```

Функция показала лучшее распределение среди всех представленных функций; тем не менее, по времени поиска (**6,677 мс**) такая хеш-таблица проигрывает предыдущим двум. Связано это с объёмом кода функции.

 ## Промежуточные итоги

:::row:::
   :::column span="":::
      **Функция**
   :::column-end:::
   :::column span="":::
      **Время поиска, мс**
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hash1
   :::column-end:::
   :::column span="":::
      510,684
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hashFirstLetter
   :::column-end:::
   :::column span="":::
      58,361
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hashWordLen
   :::column-end:::
   :::column span="":::
      75,953
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hashSum
   :::column-end:::
   :::column span="":::
      6,584
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hashRol
   :::column-end:::
   :::column span="":::
      5,919
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      hashRor
   :::column-end:::
   :::column span="":::
      6,074
   :::column-end:::
:::row-end:::
:::row:::
   :::column span="":::
      murmurHash2
   :::column-end:::
   :::column span="":::
      6,677
   :::column-end:::
:::row-end:::

Из рассмотренных нами хеш-функций практическое применение могут иметь последние четыре, при этом, применение hashSum, как обговорено выше, имеет смысл только на ограниченном диапазоне размеров хеш-таблиц. **hashRor** и **hashRol** довольно хорошо показали себя в наших условиях в силу малого числа инструкций, однако их распределение сложно назвать близким к идеальному, что на большем количестве данных может сыграть не в лучшую сторону. Лучшим вариантом кажется **murmurHash2** за счёт сравнительно малого кода и хорошего распределения - с ней я и планирую работать дальше

 ## Оптимизация

Я намерен оптимизировать поиск, поскольку эта операция наиболее часто применяется при работе с хеш-таблицами. Для начала я хочу использовать все варианты, не нарушающие кросс-платформенности

 ### Флаги компиляции

